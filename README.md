# [CarVision](https://image-classify.vercel.app/predictions)

## Equipe üë∑‚Äç‚ôÇÔ∏è

- Bruno Henrique Miranda de Oliveira (25459333)
- Raul Semicek Coelho (25891651)
- Bruno Vinicius Martins Faria (25806939)
- Nicolas Fernandes (26387085)

## Tema üöó

- Sistema de classifica√ß√£o de carros

## Objetivos üéØ
- Criar um sistema que classifique marcas de carros

## Banco de dados üìù
- <b>URL</b>: [stanford-cars-dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset)
- <b>N√∫mero de classes/marcas</b>: 196
- <b>N√∫mero de imagens</b>: 16.185

### Agradecimentos ao Banco de Dados
[Dados provenientes do Laborat√≥rio de IA da Universidade de Stanford](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)

3D Object Representations for Fine-Grained Categorization

Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei

4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.

## Revis√£o da literatura üìñ

### Artigo 1
[Reconhecimento de silhueta de autom√≥veis para carros aut√¥nomos utilizando aprendizado de m√°quina](https://wiki.sj.ifsc.edu.br/images/e/e8/TCC1_Tamara_Arrigoni.pdf)

### Objetivos 
<p>Os objetivos do artigo foi desenvolver um sistema para investigar e aplicar t√©cnicas e algoritmos de aprendizado de m√°quina, analisar o desempenho das t√©cnicas de acordo com um conjunto de dados pr√©-definido e definir, a partir dos resultados de testes, as t√©cnicas que mais se ad√©quam ao objetivo geral do projeto.<p/>

### Banco de dados utilizado
<p>Para o desenvolvimento deste trabalho uma base de dados dispon√≠vel no reposit√≥rio de aprendizado de m√°quina da Universidade da Calif√≥rnia, Irvine, foi utilizada<p/>

### Modelos utilizados
Foram utilizados alguns modelos para verificar a acur√°cia do sistema:
- Modelo baseado em Redes Neurais Artificiais
- Modelo baseado em M√°quina de Vetores de Suporte
- Modelos baseados em √Årvores de Decis√£o (C5.0/CART)
- Modelo baseado em Random Forest
- Modelo baseado em K-Nearest Neighbors (k-NN)
- Modelo baseado em Naive Bayes
- Modelo baseado em K-means

### Resultados obtidos
A acur√°cia de cada modelo foi dada por:
- Redes Neurais Artificiais: 83,33%
- M√°quina de Vetores de Suporte: 79,17%
- √Årvores de Decis√£o(C5.0): 72,62%
- √Årvores de Decis√£o(CART): 69,05%
- Random Forest: 71,43%
- K-Nearest Neighbors(k-NN): 74,40%
- Naive Bayes: 62,50%
- K-means: 41,07%

  <hr>

### Artigo 2
[T√©cnicas de PDI e Intelig√™ncia Artificial Aplicadas ao Reconhecimento de placas de Carro nos Padr√µes Brasileiros](https://www.researchgate.net/profile/Edson-Cavalcanti-Neto/publication/262956949_TECNICAS_DE_PDI_E_INTELIGENCIA_ARTIFICIAL_APLICADAS_AO_RECONHECIMENTO_DE_PLACAS_DE_CARRO_NOS_PADROES_BRASILEIROS/links/0c96053970df6e1d49000000/TECNICAS-DE-PDI-E-INTELIGENCIA-ARTIFICIAL-APLICADAS-AO-RECONHECIMENTO-DE-PLACAS-DE-CARRO-NOS-PADROES-BRASILEIROS.pdf)

### Objetivos 
Este trabalho tem como objetivo o desenvolvimento de t√©cnicas de Processamento Digital de Imagem e Inteig√™ncia Computacional com o foco em sistema de detec√ß√£o e reconhecimento de placas de ve√≠culos nos padr√µes brasileiros.

### Banco de dados utilizado
N√£o informado

### Modelos utilizados
- Filtros operadores gradiente (Roberts, Prewwit, Sobel)
- Filtro de Canny
- Transformada de Hough
- RNA MLP (Rede Neural Artificial / Multi Layer Perceptron)

### Resultados obtidos
<p>No teste do sistema foi utilizado 700 v√≠deos e a partir destes foram extra√≠das 12000 imagens.</p>
<p>A etapa do PDI desta forma obteve uma taxa de acerto de 97.02%.</p>
<p>A etapa de reconhecimento uma taxa de acerto de 97.7% em rela√ß√£o aos n√∫meros das placas e 96.4% em rela√ß√£o as letras.</p>
<p>No processo inteiro obteve-se <b>97.3%</b> de acerto na extra√ß√£o e reconhecimento dos n√∫meros e <b>96.16%</b> nos caracteres</p>

<hr>

### Artigo 3
[T√âCNICAS DE CLASSIFICA√á√ÉO DE IMAGENS PARA AN√ÅLISE DE COBERTURA VEGETAL](https://www.scielo.br/j/eagri/a/NfyXzM9DZsx5g3gnCQgCSsg/?lang=pt)

### Objetivos 
O artigo defende e explica as t√©cnicas de sensoriamento remoto para subsidiar decis√µes na √°rea agrosilvopastoral, com √™nfase na compreens√£o dos processos envolvidos e na comunica√ß√£o dos resultados de forma acess√≠vel.
### Banco de dados utilizado
Imagens retiradas com sensores e sat√©lites
### Modelos utilizados
Modelo de classifica√ß√£o supervisionada;
Modelo de classifica√ß√£o n√£o-supervisionada;
Modelo de classifica√ß√£o h√≠brida;

### Resultados obtidos
Melhora na an√°lise de ocupa√ß√£o do solo
<hr>

### Artigo 4

[CLASSIFICA√á√ÉO DE IMAGENS DERMATOSC√ìPICAS COM MACHINE LEARNING](https://bdtd.ucb.br:8443/jspui/bitstream/tede/2802/2/JulioCezarDissertacao2020.pdf)

### Objetivos 
O artigo tem como objetivo detalhar o desenvolvimento de um aplicativo utilizando machine learning para auxiliar no diagn√≥stico precoce de melanoma. Para alcan√ßar os objetyivos do trabalho deve ser considerado os seguintes objetivos.

1. Realizar uma revis√£o de literatura sobre o emprego de machine learning na identifica√ß√£o de melanoma utilizando imagens dermatosc√≥picas;
2. Identificar bancos de imagens dermatosc√≥picas para treinar e validar o modelo de machine learning;
3. Desenvolver um modelo de machine learning para classificar imagens dermatosc√≥picas em duas categorias: Melanoma e N√£o Melanoma;
4. Desenvolver uma aplica√ß√£o para viabilizar o uso do modelo;
5. Propor um protocolo de utiliza√ß√£o do classificador pelos Dermatologistas.

### Banco de dados utilizado

Identificar bancos de imagens dermatosc√≥picas para treinar e validar o modelo de machine learning;

### Modelos utilizados

Modelo de machine learning

### Resultados obtidos

Foi poss√≠vel obter um modelo de machine learning capaz de classificar imagens dermatosc√≥picas para detec√ß√£o de melanoma. O modelo obteve a precis√£o de 94% no processo de treinamento e valida√ß√£o.

## Materiais e M√©todos ‚ö°
### Metodologia
**Pr√©-processamento de dados:**
  - Carregamento das anota√ß√µes de treinamento e valida√ß√£o a partir de arquivos CSV.
  - Defini√ß√£o das classes a serem usadas no treinamento e filtro das anota√ß√µes com base nessas classes.
  - Utiliza√ß√£o do ImageDataGenerator para pr√©-processamento e aumenta√ß√£o de dados, incluindo redimensionamento, normaliza√ß√£o, e v√°rias t√©cnicas de aumenta√ß√£o (como espelhamento horizontal e vertical, rota√ß√£o, zoom e ajustes de brilho).

**Visualiza√ß√£o dos dados:**
  - Exibi√ß√£o de algumas imagens transformadas dos conjuntos de dados de treinamento para verificar se as transforma√ß√µes est√£o corretas.

**Defini√ß√£o do modelo:**
  - Utiliza√ß√£o da arquitetura VGG16 pr√©-treinada no conjunto de dados ImageNet, removendo a parte superior do modelo.
  - Adi√ß√£o de camadas densas, normaliza√ß√£o por lotes e dropout para construir a nova cabe√ßa de classifica√ß√£o.
  - Defini√ß√£o de algumas camadas da VGG16 como n√£o trein√°veis, dependendo do n√≠vel de fine-tuning especificado.

**Defini√ß√£o da fun√ß√£o de perda e otimizador:**
  - Utiliza√ß√£o da fun√ß√£o de perda categorical_crossentropy.
  - Utiliza√ß√£o do otimizador Adam com uma taxa de aprendizado ajustada.

**Treinamento do modelo:**
  - La√ßo de treinamento por v√°rias √©pocas, onde cada √©poca inclui:
      - La√ßo de treinamento sobre os lotes de dados de treinamento.
      - Avalia√ß√£o do desempenho do modelo no conjunto de dados de valida√ß√£o ap√≥s cada √©poca.
      - Utiliza√ß√£o de callbacks, como PlotLossesCallback, ModelCheckpoint, EarlyStopping e ReduceLROnPlateau, para monitorar o desempenho do modelo, salvar o melhor modelo, parar o treinamento cedo se necess√°rio, e ajustar a taxa de aprendizado.

**Avalia√ß√£o do modelo:**
  - Avalia√ß√£o do modelo treinado no conjunto de dados de treinamento e valida√ß√£o para calcular as m√©tricas de perda e precis√£o
  - Carregamento do melhor modelo salvo e c√°lculo da precis√£o final e da matriz de confus√£o no conjunto de dados de teste

**Salvamento do modelo:**
  - Salvamento do modelo treinado com melhor desempenho no conjunto de dados de teste.

**Salvamento do modelo:**
  - Realiza√ß√£o de predi√ß√µes no conjunto de dados de valida√ß√£o usando o melhor modelo salvo.
  - C√°lculo e exibi√ß√£o da matriz de confus√£o e do relat√≥rio de classifica√ß√£o para avaliar o desempenho do modelo em termos de precis√£o, recall e F1-score para cada classe.

## Resultados üèÅ

### Sem modelo pr√©-treinado
  - Configura√ß√µes do modelo:
    - Tamanho da imagem de entrada: (224, 224)
    - Formato da entrada: (224, 224, 3)
    - Tamanho do lote: 32
    - N√∫mero de √©pocas: 100
    - N√∫mero de classes: 196

  - M√©tricas de desempenho:
    - Precis√£o no conjunto de treinamento: 0.008
    - Precis√£o no conjunto de valida√ß√£o: 0.010
    - Perda no conjunto de treinamento: 5.270
    - Perda no conjunto de valida√ß√£o: 5.295
  
  - Precis√£o (Accuracy):
    - O gr√°fico de precis√£o mostra que a precis√£o no treinamento aumentou ligeiramente nas primeiras √©pocas, mas estabilizou em torno de 0.008.
    - A precis√£o no conjunto de valida√ß√£o permaneceu constante em 0.010 ao longo do treinamento.

  - Perda (Loss):
    - O gr√°fico de perda mostra que a perda no treinamento diminuiu continuamente ao longo das √©pocas, come√ßando em 5.282 e diminuindo para 5.270.
    - A perda no conjunto de valida√ß√£o aumentou levemente ao longo das √©pocas, come√ßando em 5.282 e aumentando para 5.295.

  Os resultados indicam que o modelo sem pr√©-treinamento n√£o conseguiu aprender adequadamente as caracter√≠sticas dos dados, resultando em uma baixa precis√£o e uma alta perda tanto no treinamento quanto na valida√ß√£o.


### Com modelo pr√©-treinado VGG16 (10 classes)
  - Configura√ß√µes do modelo:
    - Tamanho da imagem de entrada: (224, 224)
    - Formato da entrada: (224, 224, 3)
    - Tamanho do lote: 32
    - N√∫mero de √©pocas: 100
   
  - M√©tricas de desempenho:
    - Precis√£o no conjunto de treinamento: 0.654
    - Precis√£o no conjunto de valida√ß√£o: 0.608
    - Perda no conjunto de treinamento: 1.109
    - Perda no conjunto de valida√ß√£o: 1.290

### Com modelo pr√©-treinado VGG16 (20 classes)
  - Configura√ß√µes do modelo:
    - Tamanho da imagem de entrada: (224, 224)
    - Formato da entrada: (224, 224, 3)
    - Tamanho do lote: 32
    - N√∫mero de √©pocas: 100
   
  - M√©tricas de desempenho:
    - Precis√£o no conjunto de treinamento: 0.909
    - Precis√£o no conjunto de valida√ß√£o: 0.703
    - Perda no conjunto de treinamento: 0.339
    - Perda no conjunto de valida√ß√£o: 0.832
